setwd('C:/Users/isoch/Google 云端硬盘/Study/1. Semester an Uni-Tuebingen/Microarray Bioinformatik/HA6')
SingleExpression <- read.table(file = 'SingleExpressionCELfiles4A6.tsv', header = T, sep = "\t", nrows = 44041,
row.names = 1)
#scatter.smooth(LRMA1$A, LRMA1$M, col='red',degree = 1)
#scatter.smooth(LRMA1$A, LRMA1$M, col='red',degree = 2)
#LRMAnormalized <- LinearRegression(LRMA1$A, LRMA2$M)
par(mfcol = c(2,3))
lo1 = loess(LRMA1$M~LRMA1$A, span = 1/16, degree = 1)
lo2 = loess(LRMA2$M~LRMA2$A, span = 1/16, degree = 1)
lo3 = loess(LRMA3$M~LRMA3$A, span = 1/16, degree = 1)
lo4 = loess(LRMA4$M~LRMA4$A, span = 1/16, degree = 1)
lo5 = loess(LRMA5$M~LRMA5$A, span = 1/16, degree = 1)
lo6 = loess(LRMA6$M~LRMA6$A, span = 1/16, degree = 1)
fA1 <- predict(lo1, LRMA1$A)
fA2 <- predict(lo2, LRMA2$A)
fA3 <- predict(lo3, LRMA3$A)
fA4 <- predict(lo4, LRMA4$A)
fA5 <- predict(lo5, LRMA5$A)
fA6 <- predict(lo6, LRMA6$A)
M_normalized1 = LRMA1$M - fA1
M_normalized2 = LRMA2$M - fA2
M_normalized3 = LRMA3$M - fA3
M_normalized4 = LRMA4$M - fA4
M_normalized5 = LRMA5$M - fA5
M_normalized6 = LRMA6$M - fA6
plot(LRMA1$A, M_normalized1, pch='.')
plot(LRMA2$A, M_normalized2, pch='.')
plot(LRMA3$A, M_normalized3, pch='.')
plot(LRMA4$A, M_normalized4, pch='.')
plot(LRMA5$A, M_normalized5, pch='.')
plot(LRMA6$A, M_normalized6, pch='.')
# Judging from the produced plots through lowess and linear regression, it is clear that the plots produced through lowess
# show more equilibrium in the polarity of the group of points. Therefore, I claim that lowess is in this case better.
baselinerank <- matrix(rank(SingleExpression$Baseline.Array))
secondlinerank <- matrix(rank(SingleExpression$Second.Array))
ranklist <- cbind(baselinerank, secondlinerank)
SE <- cbind(SingleExpression, ranklist)
colnames(SE)[3:4] <- c("baserank", "secondrank")
k = nrow(SE)
tl = 0.003
th = 0.008
invagenebase = c()
invagenesecond = c()
size = rbind(NULL)
for (i in c(1:k)) {
di = abs(SE[i, 3] - SE[i, 4]) / k
rm = (SE[i, 3] + SE[i, 4]) / 2
if(((di <= th) & (rm >= k/2)) | ((di <= tl) & (rm <= k/2))){
invagenebase = rbind(invagenebase, SE[i, 1])
invagenesecond = rbind(invagenesecond, SE[i, 2])
}
size = rbind(size, nrow(invagenebase))
}
invagene = cbind(invagenebase, invagenesecond)
colnames(invagene)[1:2] <- c("base", "second")
plot(c(1: nrow(size)), size, xlab = "Times of Iteration", ylab = "Size of the Set", type = "l", col = "red",
main = "Times of Iteration X Size of the Set")
invalr <- LinearRegression(invagene[,1], invagene[,2])
complr <- LinearRegression(SE$Baseline.Array, SE$Second.Array)
plot(SE$Baseline.Array, complr$modifiedchannel, pch=5, main = "Complete Normalized Data")
abline(a=complr$a, b=complr$b, col="blue", lty=3, lwd=3)
normalizedsecond <- as.matrix((SE$Second.Array - invalr$a) / invalr$b)
plot(SE$Baseline.Array, normalizedsecond[,1], pch=5,
main = "Normalized Data through linear regression of invariant genes")
abline(a=invalr$a, b=invalr$b, col="blue", lty=3, lwd=3)
# It is clear that the linear regression based on invariant genes would give us a better visualized outcome
# because of the equilibrium of expression values with lower fluctuation.
setwd('D:Google Drive/Study/1. Semester an Uni-Tuebingen/Microarray Bioinformatik/HA6')
SingleExpression <- read.table(file = 'SingleExpressionCELfiles4A6.tsv', header = T, sep = "\t", nrows = 44041,
row.names = 1)
#scatter.smooth(LRMA1$A, LRMA1$M, col='red',degree = 1)
#scatter.smooth(LRMA1$A, LRMA1$M, col='red',degree = 2)
#LRMAnormalized <- LinearRegression(LRMA1$A, LRMA2$M)
par(mfcol = c(2,3))
lo1 = loess(LRMA1$M~LRMA1$A, span = 1/16, degree = 1)
lo2 = loess(LRMA2$M~LRMA2$A, span = 1/16, degree = 1)
lo3 = loess(LRMA3$M~LRMA3$A, span = 1/16, degree = 1)
lo4 = loess(LRMA4$M~LRMA4$A, span = 1/16, degree = 1)
lo5 = loess(LRMA5$M~LRMA5$A, span = 1/16, degree = 1)
lo6 = loess(LRMA6$M~LRMA6$A, span = 1/16, degree = 1)
fA1 <- predict(lo1, LRMA1$A)
fA2 <- predict(lo2, LRMA2$A)
fA3 <- predict(lo3, LRMA3$A)
fA4 <- predict(lo4, LRMA4$A)
fA5 <- predict(lo5, LRMA5$A)
fA6 <- predict(lo6, LRMA6$A)
M_normalized1 = LRMA1$M - fA1
M_normalized2 = LRMA2$M - fA2
M_normalized3 = LRMA3$M - fA3
M_normalized4 = LRMA4$M - fA4
M_normalized5 = LRMA5$M - fA5
M_normalized6 = LRMA6$M - fA6
plot(LRMA1$A, M_normalized1, pch='.')
plot(LRMA2$A, M_normalized2, pch='.')
plot(LRMA3$A, M_normalized3, pch='.')
plot(LRMA4$A, M_normalized4, pch='.')
plot(LRMA5$A, M_normalized5, pch='.')
plot(LRMA6$A, M_normalized6, pch='.')
# Judging from the produced plots through lowess and linear regression, it is clear that the plots produced through lowess
# show more equilibrium in the polarity of the group of points. Therefore, I claim that lowess is in this case better.
baselinerank <- matrix(rank(SingleExpression$Baseline.Array))
secondlinerank <- matrix(rank(SingleExpression$Second.Array))
ranklist <- cbind(baselinerank, secondlinerank)
SE <- cbind(SingleExpression, ranklist)
colnames(SE)[3:4] <- c("baserank", "secondrank")
k = nrow(SE)
tl = 0.003
th = 0.008
invagenebase = c()
invagenesecond = c()
size = rbind(NULL)
for (i in c(1:k)) {
di = abs(SE[i, 3] - SE[i, 4]) / k
rm = (SE[i, 3] + SE[i, 4]) / 2
if(((di <= th) & (rm >= k/2)) | ((di <= tl) & (rm <= k/2))){
invagenebase = rbind(invagenebase, SE[i, 1])
invagenesecond = rbind(invagenesecond, SE[i, 2])
}
size = rbind(size, nrow(invagenebase))
}
invagene = cbind(invagenebase, invagenesecond)
colnames(invagene)[1:2] <- c("base", "second")
plot(c(1: nrow(size)), size, xlab = "Times of Iteration", ylab = "Size of the Set", type = "l", col = "red",
main = "Times of Iteration X Size of the Set")
invalr <- LinearRegression(invagene[,1], invagene[,2])
complr <- LinearRegression(SE$Baseline.Array, SE$Second.Array)
plot(SE$Baseline.Array, complr$modifiedchannel, pch=5, main = "Complete Normalized Data")
abline(a=complr$a, b=complr$b, col="blue", lty=3, lwd=3)
normalizedsecond <- as.matrix((SE$Second.Array - invalr$a) / invalr$b)
plot(SE$Baseline.Array, normalizedsecond[,1], pch=5,
main = "Normalized Data through linear regression of invariant genes")
abline(a=invalr$a, b=invalr$b, col="blue", lty=3, lwd=3)
# It is clear that the linear regression based on invariant genes would give us a better visualized outcome
# because of the equilibrium of expression values with lower fluctuation.
# Programming functions
LinearRegression = function(x, y){
xm <- mean(x)
ym <- mean(y)
b <- sum((x-xm) * (y-ym)) / sum((x-xm)**2)
a <- ym - b*xm
return(list(a=a, b=b, gerade=function(z) a+b*z,
modifiedchannel=(y-a)/b))
}
# Reading Files
setwd("D:/Google Drive/Study/1. Semester an Uni-Tuebingen/Microarray Bioinformatik/HA5")
affy <- (read.table('affy_data.tsv', header = TRUE, row.names = 1))[1:54851,]
# Programming functions
LinearRegression = function(x, y){
xm <- mean(x)
ym <- mean(y)
b <- sum((x-xm) * (y-ym)) / sum((x-xm)**2)
a <- ym - b*xm
return(list(a=a, b=b, gerade=function(z) a+b*z,
modifiedchannel=(y-a)/b))
}
# Calculating linear regression of each pair probe
LR1 <- LinearRegression(affy$E13R021_P001.CEL, affy$E13R021_P002.CEL)
LR2 <- LinearRegression(affy$E13R021_P001.CEL, affy$E13R021_P005.CEL)
LR3 <- LinearRegression(affy$E13R021_P001.CEL, affy$E13R021_P011.CEL)
LR4 <- LinearRegression(affy$E13R021_P002.CEL, affy$E13R021_P005.CEL)
LR5 <- LinearRegression(affy$E13R021_P002.CEL, affy$E13R021_P011.CEL)
LR6 <- LinearRegression(affy$E13R021_P005.CEL, affy$E13R021_P011.CEL)
# Plotting original datas
par(mfcol=c(2,3))
plot(affy$E13R021_P001.CEL, affy$E13R021_P002.CEL, pch=20)
abline(a=LR1$a, b=LR1$b, col='blue', lwd=3, lty=1)
plot(affy$E13R021_P001.CEL, affy$E13R021_P005.CEL, pch=20)
abline(a=LR2$a, b=LR2$b, col='blue', lwd=3, lty=1)
plot(affy$E13R021_P001.CEL, affy$E13R021_P011.CEL, pch=20)
abline(a=LR3$a, b=LR3$b, col='blue', lwd=3, lty=1)
plot(affy$E13R021_P002.CEL, affy$E13R021_P005.CEL, pch=20)
abline(a=LR4$a, b=LR4$b, col='blue', lwd=3, lty=1)
plot(affy$E13R021_P002.CEL, affy$E13R021_P011.CEL, pch=20)
abline(a=LR5$a, b=LR5$b, col='blue', lwd=3, lty=1)
plot(affy$E13R021_P005.CEL, affy$E13R021_P011.CEL, pch=20)
abline(a=LR6$a, b=LR6$b, col='blue', lwd=3, lty=1)
# Plotting normalized data
plot(affy$E13R021_P001.CEL, LR1$modifiedchannel, pch=20)
abline(a=LR1$a, b=LR1$b, col='blue', lwd=3, lty=1)
plot(affy$E13R021_P001.CEL, LR2$modifiedchannel, pch=20)
abline(a=LR2$a, b=LR2$b, col='blue', lwd=3, lty=1)
plot(affy$E13R021_P001.CEL, LR3$modifiedchannel, pch=20)
abline(a=LR3$a, b=LR3$b, col='blue', lwd=3, lty=1)
plot(affy$E13R021_P002.CEL, LR4$modifiedchannel, pch=20)
abline(a=LR4$a, b=LR4$b, col='blue', lwd=3, lty=1)
plot(affy$E13R021_P002.CEL, LR5$modifiedchannel, pch=20)
abline(a=LR5$a, b=LR5$b, col='blue', lwd=3, lty=1)
plot(affy$E13R021_P005.CEL, LR6$modifiedchannel, pch=20)
abline(a=LR6$a, b=LR6$b, col='blue', lwd=3, lty=1)
# Processing data with log2 function
affylog2 <- log2(affy)
# Loading library affy
library(affy)
# Programming MA calculating function
MA = function(x,y){
M <- x-y
A <- (x+y)/2
M_mean <- mean(M)
A_mean <- mean(A)
b <- sum((M-M_mean) * (A-A_mean)) / sum((A-A_mean)**2)
a <- M_mean - b*A_mean
return(list(M=M, A=A, a=a, b=b, regression=function(z) a+b*z, modifiedchannel=(M-a)/b ))
}
# Calculating
LRMA1 <- MA(affylog2$E13R021_P001.CEL, affylog2$E13R021_P002.CEL)
LRMA2 <- MA(affylog2$E13R021_P001.CEL, affylog2$E13R021_P005.CEL)
LRMA3 <- MA(affylog2$E13R021_P001.CEL, affylog2$E13R021_P011.CEL)
LRMA4 <- MA(affylog2$E13R021_P002.CEL, affylog2$E13R021_P005.CEL)
LRMA5 <- MA(affylog2$E13R021_P002.CEL, affylog2$E13R021_P011.CEL)
LRMA6 <- MA(affylog2$E13R021_P005.CEL, affylog2$E13R021_P011.CEL)
# Plotting MA Plot with Linear Regression line
plot(LRMA1$A, LRMA1$M, xlab = 'A', ylab = 'M', pch=20)
abline(a=LRMA1$a, b=LRMA1$b, col='red', lwd=1)
plot(LRMA2$A, LRMA2$M, xlab = 'A', ylab = 'M', pch=20)
abline(a=LRMA2$a, b=LRMA2$b, col='red', lwd=1)
plot(LRMA3$A, LRMA3$M, xlab = 'A', ylab = 'M', pch=20)
abline(a=LRMA3$a, b=LRMA3$b, col='red', lwd=1)
plot(LRMA4$A, LRMA4$M, xlab = 'A', ylab = 'M', pch=20)
abline(a=LRMA4$a, b=LRMA4$b, col='red', lwd=1)
plot(LRMA5$A, LRMA5$M, xlab = 'A', ylab = 'M', pch=20)
abline(a=LRMA5$a, b=LRMA5$b, col='red', lwd=1)
plot(LRMA6$A, LRMA6$M, xlab = 'A', ylab = 'M', pch=20)
abline(a=LRMA6$a, b=LRMA6$b, col='red', lwd=1)
# Plotting Normalized MA Plot with Linear Regression line
plot(LRMA1$A, LRMA1$modifiedchannel, xlab = 'A', ylab = 'M', pch=20)
abline(a=LRMA1$a, b=LRMA1$b, col='red', lwd=1)
plot(LRMA2$A, LRMA2$modifiedchannel, xlab = 'A', ylab = 'M', pch=20)
abline(a=LRMA2$a, b=LRMA2$b, col='red', lwd=1)
plot(LRMA3$A, LRMA3$modifiedchannel, xlab = 'A', ylab = 'M', pch=20)
abline(a=LRMA3$a, b=LRMA3$b, col='red', lwd=1)
plot(LRMA4$A, LRMA4$modifiedchannel, xlab = 'A', ylab = 'M', pch=20)
abline(a=LRMA4$a, b=LRMA4$b, col='red', lwd=1)
plot(LRMA5$A, LRMA5$modifiedchannel, xlab = 'A', ylab = 'M', pch=20)
abline(a=LRMA5$a, b=LRMA5$b, col='red', lwd=1)
plot(LRMA6$A, LRMA6$modifiedchannel, xlab = 'A', ylab = 'M', pch=20)
abline(a=LRMA6$a, b=LRMA6$b, col='red', lwd=1)
# After linear regression normalization, the coordinate was reset according to the results of linear regression.
# The vertical values were adjusted to a normalized level.
# Linear regression can be directly applied to scatterplot, but not to MA-plot.
# M'= M-f(A)
